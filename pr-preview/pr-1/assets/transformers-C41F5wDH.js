import{F as Pe,g as Ce,c as Y,m as j,a as ze,T as C,b as de,i as U,s as ie,d as Se,e as E,f as ve,C as re,h as Ee,j as Le,A as Ie,k as $,l as S,n as Be,o as Re,p as De,q as Oe,r as je,t as Ve,u as Ne,v as qe,w as Ge,x as We,y as Xe,z as $e,B as Ue,D as He,E as ue,G as Qe,H as oe,I as Ze,J as Je,K as Ye,L as Ke,M as et,R as H,N as ee,O as he,P as tt,Q as st}from"./index-VzR9KbVR.js";import{bO as Ms,bN as bs,bM as ws,b5 as ys,b4 as Ts,b3 as xs,b2 as Fs,b1 as ks,eX as As,fD as Ps,bh as Cs,bi as zs,bg as Ss,bf as vs,f9 as Es,c_ as Ls,cZ as Is,cY as Bs,Y as Rs,$ as Ds,Z as Os,_ as js,X as Vs,W as Ns,eW as qs,bq as Gs,bp as Ws,bo as Xs,bt as $s,bs as Us,br as Hs,fx as Qs,fw as Zs,cx as Js,cw as Ys,cv as Ks,fd as eo,bU as to,bT as so,c3 as oo,c2 as ao,c1 as no,bV as io,fs as ro,bW as lo,am as co,ap as uo,an as ho,ao as fo,al as po,ak as mo,f4 as _o,eR as go,c0 as Mo,b$ as bo,ez as wo,ex as yo,ew as To,ey as xo,cl as Fo,ck as ko,cj as Ao,fr as Po,ff as Co,fB as zo,aa as So,ad as vo,ab as Eo,ac as Lo,a9 as Io,a8 as Bo,f1 as Ro,dy as Do,dx as Oo,dw as jo,dB as Vo,dA as No,dz as qo,dn as Go,dm as Wo,dl as Xo,as as $o,av as Uo,at as Ho,au as Qo,ar as Zo,aq as Jo,e_ as Yo,ay as Ko,aB as ea,az as ta,aA as sa,ax as oa,aw as aa,e$ as na,db as ia,da as ra,d9 as la,dq as ca,dp as da,d1 as ua,d2 as ha,d0 as fa,d3 as pa,c$ as ma,d4 as _a,dE as ga,dD as Ma,dC as ba,aH as wa,aG as ya,aE as Ta,aF as xa,aD as Fa,aC as ka,f3 as Aa,dv as Pa,du as Ca,eJ as za,eI as Sa,eH as va,ag as Ea,aj as La,ah as Ia,ai as Ba,af as Ra,ae as Da,f6 as Oa,aK as ja,aL as Va,aM as Na,aJ as qa,aI as Ga,fk as Wa,ev as Xa,eu as $a,et as Ua,fi as Ha,cJ as Qa,cI as Za,cH as Ja,dt as Ya,ds as Ka,dr as en,c6 as tn,c5 as sn,c4 as on,f8 as an,ci as nn,ch as rn,cg as ln,cf as cn,ce as dn,cd as un,c9 as hn,c8 as fn,c7 as pn,cc as mn,cb as _n,ca as gn,fj as Mn,fm as bn,fn as wn,f0 as yn,e9 as Tn,ea as xn,e8 as Fn,eS as kn,co as An,cn as Pn,cm as Cn,fe as zn,bb as Sn,ba as vn,b9 as En,dR as Ln,dQ as In,dP as Bn,fp as Rn,fb as Dn,bn as On,bl as jn,bm as Vn,bk as Nn,bj as qn,fa as Gn,aU as Wn,aX as Xn,aV as $n,aW as Un,aT as Hn,aS as Qn,fh as Zn,be as Jn,bd as Yn,bc as Kn,dO as ei,dN as ti,dM as si,fu as oi,eP as ai,ep as ni,eo as ii,en as ri,aP as li,aR as ci,aQ as di,aO as ui,aN as hi,eY as fi,cO as pi,cN as mi,cM as _i,cR as gi,cQ as Mi,cP as bi,V as wi,cA as yi,cz as Ti,cy as xi,fo as Fi,a1 as ki,a0 as Ai,fz as Pi,cD as Ci,cC as zi,cB as Si,cU as vi,cT as Ei,cS as Li,cX as Ii,cW as Bi,cV as Ri,cu as Di,ct as Oi,cs as ji,U as Vi,eV as Ni,fC as qi,eK as Gi,eQ as Wi,cr as Xi,cq as $i,cp as Ui,fl as Hi,de as Qi,dd as Zi,dc as Ji,a4 as Yi,a7 as Ki,a5 as er,a6 as tr,a3 as sr,a2 as or,f2 as ar,bw as nr,bz as ir,bx as rr,by as lr,bv as cr,bu as dr,fc as ur,dL as hr,dK as fr,dJ as pr,eD as mr,eE as _r,eC as gr,eL as Mr,eM as br,bY as wr,bX as yr,bZ as Tr,ft as xr,b_ as Fr,ei as kr,ej as Ar,ek as Pr,eh as Cr,fy as zr,a_ as Sr,b0 as vr,a$ as Er,aZ as Lr,aY as Ir,eZ as Br,eG as Rr,eF as Dr,es as Or,er as jr,eq as Vr,dk as Nr,dj as qr,di as Gr,dh as Wr,dg as Xr,df as $r,b8 as Ur,b7 as Hr,b6 as Qr,f7 as Zr,d7 as Jr,d6 as Yr,d8 as Kr,d5 as el,eO as tl,eU as sl,em as ol,el as al,dZ as nl,d_ as il,dY as rl,dX as ll,e3 as cl,e1 as dl,e2 as ul,e0 as hl,d$ as fl,cG as pl,cF as ml,cE as _l,bS as gl,cL as Ml,cK as bl,eB as wl,eT as yl,eA as Tl,fA as xl,e6 as Fl,e7 as kl,e5 as Al,e4 as Pl,fv as Cl,dW as zl,dU as Sl,dV as vl,dT as El,dS as Ll,eg as Il,ed as Bl,ee as Rl,ef as Dl,ec as Ol,eb as jl,bR as Vl,bQ as Nl,bP as ql,fq as Gl,bF as Wl,bD as Xl,bE as $l,bB as Ul,bA as Hl,bI as Ql,bL as Zl,bJ as Jl,bK as Yl,bH as Kl,bG as ec,fg as tc,f5 as sc,bC as oc,eN as ac,dH as nc,dG as ic,dI as rc,dF as lc,fH as cc,S as dc,fK as uc,fM as hc,fG as fc,fN as pc,fI as mc,fJ as _c,fE as gc,fL as Mc,fF as bc}from"./index-VzR9KbVR.js";async function ot(i,e){if(typeof AudioContext>"u")throw Error("Unable to load audio from path/URL since `AudioContext` is not available in your environment. Instead, audio data should be passed directly to the pipeline/processor. For more information and some example code, see https://huggingface.co/docs/transformers.js/guides/node-audio-processing.");const t=await(await Ce(i)).arrayBuffer(),s=new AudioContext({sampleRate:e});typeof e>"u"&&console.warn(`No sampling rate provided, using default of ${s.sampleRate}Hz.`);const a=await s.decodeAudioData(t);let o;if(a.numberOfChannels===2){const n=Math.sqrt(2),r=a.getChannelData(0),l=a.getChannelData(1);o=new Float32Array(r.length);for(let c=0;c<a.length;++c)o[c]=n*(r[c]+l[c])/2}else o=a.getChannelData(0);return o}function fe(i){if(i<1)return new Float64Array;if(i===1)return new Float64Array([1]);const e=i-1,t=Math.PI/e,s=new Float64Array(i);for(let a=0;a<i;++a){const o=2*a-e;s[a]=.5+.5*Math.cos(t*o)}return s}const at={htk:i=>2595*Math.log10(1+i/700),kaldi:i=>1127*Math.log(1+i/700),slaney:(i,e=1e3,t=15,s=27/Math.log(6.4))=>i>=e?t+Math.log(i/e)*s:3*i/200};function ae(i,e="htk"){const t=at[e];if(!t)throw new Error('mel_scale should be one of "htk", "slaney" or "kaldi".');return typeof i=="number"?t(i):i.map(s=>t(s))}const nt={htk:i=>700*(10**(i/2595)-1),kaldi:i=>700*(Math.exp(i/1127)-1),slaney:(i,e=1e3,t=15,s=Math.log(6.4)/27)=>i>=t?e*Math.exp(s*(i-t)):200*i/3};function it(i,e="htk"){const t=nt[e];if(!t)throw new Error('mel_scale should be one of "htk", "slaney" or "kaldi".');return typeof i=="number"?t(i):i.map(s=>t(s))}function rt(i,e){const t=Float64Array.from({length:e.length-1},(n,r)=>e[r+1]-e[r]),s=Array.from({length:i.length},()=>new Array(e.length));for(let n=0;n<i.length;++n){const r=s[n];for(let l=0;l<e.length;++l)r[l]=e[l]-i[n]}const a=e.length-2,o=Array.from({length:a},()=>new Array(i.length));for(let n=0;n<i.length;++n){const r=s[n];for(let l=0;l<a;++l){const c=-r[l]/t[l],d=r[l+2]/t[l+1];o[l][n]=Math.max(0,Math.min(c,d))}}return o}function pe(i,e,t){const s=(e-i)/(t-1);return Float64Array.from({length:t},(a,o)=>i+s*o)}function Q(i,e,t,s,a,o=null,n="htk",r=!1){if(o!==null&&o!=="slaney")throw new Error('norm must be one of null or "slaney"');const l=ae(t,n),c=ae(s,n),d=pe(l,c,e+2);let f=it(d,n),p;if(r){const h=a/(i*2);p=ae(Float64Array.from({length:i},(m,_)=>_*h),n),f=d}else p=pe(0,Math.floor(a/2),i);const u=rt(p,f);if(o!==null&&o==="slaney")for(let h=0;h<e;++h){const m=u[h],_=2/(f[h+2]-f[h]);for(let g=0;g<i;++g)m[g]*=_}return u}function lt(i,e,t){const s=new i.constructor(i.length+e+t),a=i.length-1;for(let o=0;o<i.length;++o)s[e+o]=i[o];for(let o=1;o<=e;++o)s[e-o]=i[Y(o,a)];for(let o=1;o<=t;++o)s[a+e+o]=i[Y(a-o,a)];return s}function Me(i,e,t,s,a){if(t<=0)throw new Error("reference must be greater than zero");if(s<=0)throw new Error("min_value must be greater than zero");t=Math.max(s,t);const o=Math.log10(t);for(let n=0;n<i.length;++n)i[n]=e*Math.log10(Math.max(s,i[n])-o);if(a!==null){if(a<=0)throw new Error("db_range must be greater than zero");const n=j(i)[0]-a;for(let r=0;r<i.length;++r)i[r]=Math.max(i[r],n)}return i}function ct(i,e=1,t=1e-5,s=null){return Me(i,20,e,t,s)}function dt(i,e=1,t=1e-10,s=null){return Me(i,10,e,t,s)}function te(i,e,t,s,{fft_length:a=null,power:o=1,center:n=!0,pad_mode:r="reflect",onesided:l=!0,preemphasis:c=null,mel_filters:d=null,mel_floor:f=1e-10,log_mel:p=null,reference:u=1,min_value:h=1e-10,db_range:m=null,remove_dc_offset:_=null,max_num_frames:g=null,do_pad:M=!0,transpose:b=!1}={}){const w=e.length;if(a===null&&(a=t),t>a)throw Error(`frame_length (${t}) may not be larger than fft_length (${a})`);if(w!==t)throw new Error(`Length of the window (${w}) must equal frame_length (${t})`);if(s<=0)throw new Error("hop_length must be greater than zero");if(o===null&&d!==null)throw new Error("You have provided `mel_filters` but `power` is `None`. Mel spectrogram computation is not yet supported for complex-valued spectrogram. Specify `power` to fix this issue.");if(n){if(r!=="reflect")throw new Error(`pad_mode="${r}" not implemented yet.`);const P=Math.floor((a-1)/2)+1;i=lt(i,P,P)}const y=Math.floor(1+Math.floor((i.length-t)/s)),T=l?Math.floor(a/2)+1:a;let A=y,B=y;g!==null&&(g>y?M&&(B=g):B=A=g);const q=new Pe(a),R=new Float64Array(a),G=new Float64Array(q.outputBufferSize),J=new Array(A);for(let P=0;P<A;++P){const z=P*s;for(let x=0;x<t;++x)R[x]=i[z+x];if(_){let x=0;for(let I=0;I<t;++I)x+=R[I];const V=x/t;for(let I=0;I<t;++I)R[I]-=V}if(c!==null){for(let x=t-1;x>=1;--x)R[x]-=c*R[x-1];R[0]*=1-c}for(let x=0;x<e.length;++x)R[x]*=e[x];q.realTransform(G,R);const L=new Array(T);for(let x=0;x<L.length;++x){const V=x<<1;L[x]=G[V]**2+G[V+1]**2}J[P]=L}if(o!==null&&o!==2){const P=2/o;for(let z=0;z<J.length;++z){const L=J[z];for(let x=0;x<L.length;++x)L[x]**=P}}const W=d.length,O=new Float32Array(W*B),Ae=b?[B,W]:[W,B];for(let P=0;P<W;++P){const z=d[P];for(let L=0;L<A;++L){const x=J[L];let V=0;for(let I=0;I<T;++I)V+=z[I]*x[I];O[b?L*W+P:P*A+L]=Math.max(f,V)}}if(o!==null&&p!==null){const P=Math.min(O.length,A*W);switch(p){case"log":for(let z=0;z<P;++z)O[z]=Math.log(O[z]);break;case"log10":for(let z=0;z<P;++z)O[z]=Math.log10(O[z]);break;case"dB":if(o===1)ct(O,u,h,m);else if(o===2)dt(O,u,h,m);else throw new Error(`Cannot use log_mel option '${p}' with power ${o}`);break;default:throw new Error(`log_mel must be one of null, 'log', 'log10' or 'dB'. Got '${p}'`)}}return{data:O,dims:Ae}}function se(i,e,{periodic:t=!0,frame_length:s=null,center:a=!0}={}){const o=t?i+1:i;let n;switch(e){case"boxcar":n=new Float64Array(o).fill(1);break;case"hann":case"hann_window":n=fe(o);break;case"povey":n=fe(o).map(r=>Math.pow(r,.85));break;default:throw new Error(`Unknown window type ${e}.`)}if(t&&(n=n.subarray(0,i)),s===null)return n;if(i>s)throw new Error(`Length of the window (${i}) may not be larger than frame_length (${s})`);return n}function ut([i,e,t,s]){return[i-t/2,e-s/2,i+t/2,e+s/2]}function le(i,e=.5,t=null,s=!1){const a=i.logits,o=i.pred_boxes,[n,r,l]=a.dims;if(t!==null&&t.length!==n)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");let c=[];for(let d=0;d<n;++d){let f=t!==null?t[d]:null,p={boxes:[],classes:[],scores:[]},u=a[d],h=o[d];for(let m=0;m<r;++m){let _=u[m],g=[],M;if(s){M=_.sigmoid().data;for(let b=0;b<M.length;++b)M[b]>e&&g.push(b)}else{let b=j(_.data)[1];if(b===l-1)continue;g.push(b),M=E(_.data)}for(const b of g){let w=h[m].data;w=ut(w),f!==null&&(w=w.map((y,T)=>y*f[(T+1)%2])),p.boxes.push(w),p.classes.push(b),p.scores.push(M[b])}}c.push(p)}return c}function Z(i,e){if(!(i instanceof Float32Array||i instanceof Float64Array))throw new Error(`${e} expects input to be a Float32Array or a Float64Array, but got ${i?.constructor?.name??typeof i} instead. If using the feature extractor directly, remember to use \`read_audio(url, sampling_rate)\` to obtain the raw audio data of the file/url.`)}function me(i,e,t=0,s=null){const a=i/e;let o=Ee(a)*e;return s!==null&&o>s&&(o=Math.floor(a)*e),o<t&&(o=Math.ceil(a)*e),o}function ne([i,e],t){return[Math.max(Math.floor(i/t),1)*t,Math.max(Math.floor(e/t),1)*t]}class N extends re{constructor(e){super(),this.config=e}}class F extends N{constructor(e){super(e),this.image_mean=this.config.image_mean??this.config.mean,this.image_std=this.config.image_std??this.config.std,this.resample=this.config.resample??2,this.do_rescale=this.config.do_rescale??!0,this.rescale_factor=this.config.rescale_factor??1/255,this.do_normalize=this.config.do_normalize,this.do_resize=this.config.do_resize,this.do_thumbnail=this.config.do_thumbnail,this.size=this.config.size,this.size_divisibility=this.config.size_divisibility??this.config.size_divisor,this.do_center_crop=this.config.do_center_crop,this.crop_size=this.config.crop_size,this.do_convert_rgb=this.config.do_convert_rgb??!0,this.do_crop_margin=this.config.do_crop_margin,this.pad_size=this.config.pad_size,this.do_pad=this.config.do_pad,this.do_pad&&!this.pad_size&&this.size&&this.size.width!==void 0&&this.size.height!==void 0&&(this.pad_size=this.size),this.do_flip_channel_order=this.config.do_flip_channel_order??!1}async thumbnail(e,t,s=2){const a=e.height,o=e.width,n=t.height,r=t.width;let l=Math.min(a,n),c=Math.min(o,r);return l===a&&c===o?e:(a>o?c=Math.floor(o*l/a):o>a&&(l=Math.floor(a*c/o)),await e.resize(c,l,{resample:s}))}async crop_margin(e,t=200){const s=e.clone().grayscale(),a=ve(s.data)[0],n=j(s.data)[0]-a;if(n===0)return e;const r=t/255;let l=s.width,c=s.height,d=0,f=0;for(let p=0;p<s.height;++p){const u=p*s.width;for(let h=0;h<s.width;++h)(s.data[u+h]-a)/n<r&&(l=Math.min(l,h),c=Math.min(c,p),d=Math.max(d,h),f=Math.max(f,p))}return e=await e.crop([l,c,d,f]),e}pad_image(e,t,s,{mode:a="constant",center:o=!1,constant_values:n=0}={}){const[r,l,c]=t;let d,f;if(typeof s=="number"?(d=s,f=s):(d=s.width,f=s.height),d!==l||f!==r){const p=new Float32Array(d*f*c);if(Array.isArray(n))for(let m=0;m<p.length;++m)p[m]=n[m%c];else n!==0&&p.fill(n);const[u,h]=o?[Math.floor((d-l)/2),Math.floor((f-r)/2)]:[0,0];for(let m=0;m<r;++m){const _=(m+h)*d,g=m*l;for(let M=0;M<l;++M){const b=(_+M+u)*c,w=(g+M)*c;for(let y=0;y<c;++y)p[b+y]=e[w+y]}}if(a==="symmetric"){if(o)throw new Error("`center` padding is not supported when `mode` is set to `symmetric`.");const m=r-1,_=l-1;for(let g=0;g<f;++g){const M=g*d,b=Y(g,m)*l;for(let w=0;w<d;++w){if(g<r&&w<l)continue;const y=(M+w)*c,T=(b+Y(w,_))*c;for(let A=0;A<c;++A)p[y+A]=e[T+A]}}}e=p,t=[f,d,c]}return[e,t]}rescale(e){for(let t=0;t<e.length;++t)e[t]=this.rescale_factor*e[t]}get_resize_output_image_size(e,t){const[s,a]=e.size;let o,n;if(this.do_thumbnail){const{height:r,width:l}=t;o=Math.min(r,l)}else Number.isInteger(t)?(o=t,n=this.config.max_size??o):t!==void 0&&(o=t.shortest_edge,n=t.longest_edge);if(o!==void 0||n!==void 0){const r=o===void 0?1:Math.max(o/s,o/a),l=s*r,c=a*r,d=n===void 0?1:Math.min(n/l,n/c);let f=Math.floor(Number((l*d).toFixed(2))),p=Math.floor(Number((c*d).toFixed(2)));return this.size_divisibility!==void 0&&([f,p]=ne([f,p],this.size_divisibility)),[f,p]}else if(t!==void 0&&t.width!==void 0&&t.height!==void 0){let r=t.width,l=t.height;if(this.config.keep_aspect_ratio&&this.config.ensure_multiple_of){let c=l/a,d=r/s;Math.abs(1-d)<Math.abs(1-c)?c=d:d=c,l=me(c*a,this.config.ensure_multiple_of),r=me(d*s,this.config.ensure_multiple_of)}return[r,l]}else{if(this.size_divisibility!==void 0)return ne([s,a],this.size_divisibility);throw new Error(`Could not resize image due to unsupported \`this.size\` option in config: ${JSON.stringify(t)}`)}}async resize(e){const[t,s]=this.get_resize_output_image_size(e,this.size);return await e.resize(t,s,{resample:this.resample})}async preprocess(e,{do_normalize:t=null,do_pad:s=null,do_convert_rgb:a=null,do_convert_grayscale:o=null,do_flip_channel_order:n=null}={}){this.do_crop_margin&&(e=await this.crop_margin(e));const[r,l]=e.size;if(a??this.do_convert_rgb?e=e.rgb():o&&(e=e.grayscale()),this.do_resize&&(e=await this.resize(e)),this.do_thumbnail&&(e=await this.thumbnail(e,this.size,this.resample)),this.do_center_crop){let u,h;Number.isInteger(this.crop_size)?(u=this.crop_size,h=this.crop_size):(u=this.crop_size.width,h=this.crop_size.height),e=await e.center_crop(u,h)}const c=[e.height,e.width];let d=Float32Array.from(e.data),f=[e.height,e.width,e.channels];if(this.do_rescale&&this.rescale(d),t??this.do_normalize){let u=this.image_mean;Array.isArray(this.image_mean)||(u=new Array(e.channels).fill(u));let h=this.image_std;if(Array.isArray(this.image_std)||(h=new Array(e.channels).fill(u)),u.length!==e.channels||h.length!==e.channels)throw new Error(`When set to arrays, the length of \`image_mean\` (${u.length}) and \`image_std\` (${h.length}) must match the number of channels in the image (${e.channels}).`);for(let m=0;m<d.length;m+=e.channels)for(let _=0;_<e.channels;++_)d[m+_]=(d[m+_]-u[_])/h[_]}if(s??this.do_pad){if(this.pad_size)[d,f]=this.pad_image(d,[e.height,e.width,e.channels],this.pad_size);else if(this.size_divisibility){const[u,h]=ne([f[1],f[0]],this.size_divisibility);[d,f]=this.pad_image(d,f,{width:u,height:h})}}if(n??this.do_flip_channel_order){if(f[2]!==3)throw new Error("Flipping channel order is only supported for RGB images.");for(let u=0;u<d.length;u+=3){const h=d[u];d[u]=d[u+2],d[u+2]=h}}const p=new C("float32",d,f).permute(2,0,1);return{original_size:[l,r],reshaped_input_size:c,pixel_values:p}}async _call(e,...t){Array.isArray(e)||(e=[e]);const s=await Promise.all(e.map(o=>this.preprocess(o)));return{pixel_values:ie(s.map(o=>o.pixel_values),0),original_sizes:s.map(o=>o.original_size),reshaped_input_sizes:s.map(o=>o.reshaped_input_size)}}}class ht extends F{post_process_semantic_segmentation(e,t=null){const s=e.logits,a=s.dims[0];if(t!==null&&t.length!==a)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");const o=[];for(let n=0;n<a;++n){const r=t!==null?t[n]:null;let l=s[n];r!==null&&(l=U(l,r,"bilinear",!1));const[c,d]=r??l.dims.slice(-2),f=new C("int32",new Int32Array(c*d),[c,d]),p=l[0].data;for(let _=1;_<l.dims[0];++_){const g=l[_].data;for(let M=0;M<g.length;++M)g[M]>p[M]&&(p[M]=g[M],f.data[M]=_)}const u=new Array(l.dims[0]),h=f.data;for(let _=0;_<h.length;++_){const g=h[_];u[g]=g}const m=u.filter(_=>_!==void 0);o.push({segmentation:f,labels:m})}return o}}class be extends F{}class ft extends be{}class pt extends F{}class mt extends F{}class _t extends F{}class gt extends F{}class Mt extends F{}class we extends F{constructor(e){super(e),this.crop_pct=this.config.crop_pct??224/256}async resize(e){const t=this.size?.shortest_edge;if(t===void 0)throw new Error("Size dictionary must contain 'shortest_edge' key.");if(t<384){const s=Math.floor(t/this.crop_pct),[a,o]=this.get_resize_output_image_size(e,{shortest_edge:s});e=await e.resize(a,o,{resample:this.resample}),e=await e.center_crop(t,t)}else e=await e.resize(t,t,{resample:this.resample});return e}}class bt extends we{}class wt extends F{}class yt extends F{}class Tt extends F{constructor(e){super(e),this.include_top=this.config.include_top??!0,this.include_top&&(this.image_std=this.image_std.map(t=>t*t))}}class ye extends F{}class xt extends ye{}class Te extends F{post_process_object_detection(...e){return le(...e)}}class Ft extends Te{}class kt extends F{}class At extends F{}class xe extends F{pad_image(e,t,s,a={}){const[o,n,r]=t;let l=this.image_mean;Array.isArray(this.image_mean)||(l=new Array(r).fill(l));let c=this.image_std;Array.isArray(c)||(c=new Array(r).fill(l));const d=l.map((f,p)=>-f/c[p]);return super.pad_image(e,t,s,{center:!0,constant_values:d,...a})}}class Pt extends xe{}class Ct extends F{async _call(e){const t=await super._call(e),s=[t.pixel_values.dims[0],64,64],a=new C("int64",new BigInt64Array(s.reduce((o,n)=>o*n)).fill(1n),s);return{...t,pixel_mask:a}}post_process_object_detection(...e){return le(...e)}remove_low_and_no_objects(e,t,s,a){let o=[],n=[],r=[];for(let l=0;l<e.dims[0];++l){let c=e[l],d=t[l],f=j(c.data)[1];if(f===a)continue;let u=E(c.data)[f];u>s&&(o.push(d),n.push(u),r.push(f))}return[o,n,r]}check_segment_validity(e,t,s,a=.5,o=.8){let n=[],r=0,l=0;for(let d=0;d<e.length;++d)e[d]===s&&(n.push(d),++r),t[s].data[d]>=a&&++l;let c=r>0&&l>0;return c&&(c=r/l>o),[c,n]}compute_segments(e,t,s,a,o,n=null,r=null){let[l,c]=r??e[0].dims,d=new C("int32",new Int32Array(l*c),[l,c]),f=[];if(r!==null)for(let m=0;m<e.length;++m)e[m]=U(e[m],r,"bilinear",!1);let p=new Int32Array(e[0].data.length),u=new Float32Array(e[0].data.length);for(let m=0;m<e.length;++m){let _=t[m];for(let g=0;g<e[m].data.length;++g)e[m].data[g]*=_,e[m].data[g]>u[g]&&(p[g]=m,u[g]=e[m].data[g])}let h=0;for(let m=0;m<s.length;++m){let _=s[m],[g,M]=this.check_segment_validity(p,e,m,a,o);if(g){++h;for(let b of M)d.data[b]=h;f.push({id:h,label_id:_,score:t[m]})}}return[d,f]}post_process_panoptic_segmentation(e,t=.5,s=.5,a=.8,o=null,n=null){o===null&&(console.warn("`label_ids_to_fuse` unset. No instance will be fused."),o=new Set);const r=e.logits,c=e.pred_masks.sigmoid();let[d,f,p]=r.dims;if(p-=1,n!==null&&n.length!==d)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");let u=[];for(let h=0;h<d;++h){let m=n!==null?n[h]:null,_=r[h],g=c[h],[M,b,w]=this.remove_low_and_no_objects(_,g,t,p);if(w.length===0){let[A,B]=m??g.dims.slice(-2),q=new C("int32",new Int32Array(A*B).fill(-1),[A,B]);u.push({segmentation:q,segments_info:[]});continue}let[y,T]=this.compute_segments(M,b,w,s,a,o,m);u.push({segmentation:y,segments_info:T})}return u}post_process_instance_segmentation(){throw Error("Not implemented yet")}}class zt extends F{post_process_object_detection(...e){return le(...e)}}class St extends F{reshape_input_points(e,t,s){e=structuredClone(e);let a=de(e);if(a.length===3)a=[1,...a],e=[e];else if(a.length!==4)throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");for(let o=0;o<e.length;++o){let n=t[o],r=s[o],l=[r[0]/n[0],r[1]/n[1]];for(let c=0;c<e[o].length;++c)for(let d=0;d<e[o][c].length;++d)for(let f=0;f<e[o][c][d].length;++f)e[o][c][d][f]*=l[f]}return new C("float32",Float32Array.from(e.flat(1/0)),a)}add_input_labels(e,t){let s=de(e);if(s.length===2)s=[1,...s],e=[e];else if(s.length!==3)throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");if(s.some((a,o)=>a!==t.dims[o]))throw Error(`The first ${s.length} dimensions of 'input_points' and 'input_labels' must be the same.`);return new C("int64",e.flat(1/0).map(BigInt),s)}async _call(e,t=null,s=null){const a=await super._call(e);if(t&&(a.input_points=this.reshape_input_points(t,a.original_sizes,a.reshaped_input_sizes)),s){if(!a.input_points)throw Error("`input_points` must be provided if `input_labels` are provided.");a.input_labels=this.add_input_labels(s,a.input_points)}return a}post_process_masks(e,t,s,{mask_threshold:a=0,binarize:o=!0,pad_size:n=null}={}){const r=[];n=n??this.pad_size;const l=[n.height,n.width];for(let c=0;c<t.length;++c){const d=t[c],f=s[c],p=e[c],u=[];for(let h=0;h<p.dims[0];++h){const m=p[h];let _=U(m,l,"bilinear",!1);if(_=_.slice(null,[0,f[0]],[0,f[1]]),_=U(_,d,"bilinear",!1),o){const g=new Uint8Array(_.data.length);for(let M=0;M<_.data.length;++M)_.data[M]>a&&(g[M]=1);_=new C("bool",g,_.dims)}u.push(_)}r.push(ie(u))}return r}}class vt extends F{pad_image(e,t,s,a={}){const[o,n,r]=t;return super.pad_image(e,t,{width:n+(s-n%s)%s,height:o+(s-o%s)%s},{mode:"symmetric",center:!1,constant_values:-1,...a})}}class Et extends F{async _call(e,t){Array.isArray(e)||(e=[e]),Array.isArray(t)||(t=[t]);const s=await Promise.all(e.map(n=>this.preprocess(n))),a=await Promise.all(t.map(n=>this.preprocess(n,{do_normalize:!1,do_convert_rgb:!1,do_convert_grayscale:!0})));return{pixel_values:ie(s.map((n,r)=>Se([n.pixel_values,a[r].pixel_values],0)),0),original_sizes:s.map(n=>n.original_size),reshaped_input_sizes:s.map(n=>n.reshaped_input_size)}}}class Lt extends N{constructor(e){super(e),this.config.mel_filters??=Q(Math.floor(1+this.config.n_fft/2),this.config.feature_size,0,8e3,this.config.sampling_rate,"slaney","slaney"),this.window=se(this.config.n_fft,"hann")}_extract_fbank_features(e){const{data:t,dims:s}=te(e,this.window,this.config.n_fft,this.config.hop_length,{power:2,mel_filters:this.config.mel_filters,log_mel:"log10",max_num_frames:this.config.nb_max_frames}),a=j(t)[0];for(let o=0;o<t.length;++o)t[o]=(Math.max(t[o],a-8)+4)/4;return{data:t,dims:s}}async _call(e){Z(e,"WhisperFeatureExtractor");let t;e.length>this.config.n_samples?(console.warn("Attempting to extract features for audio longer than 30 seconds. If using a pipeline to extract transcript from a long audio clip, remember to specify `chunk_length_s` and/or `stride_length_s`."),t=e.slice(0,this.config.n_samples)):(t=new Float32Array(this.config.n_samples),t.set(e));const{data:s,dims:a}=this._extract_fbank_features(t);return{input_features:new C("float32",s,[1,...a])}}}class It extends N{_zero_mean_unit_var_norm(e){const s=e.reduce((o,n)=>o+n,0)/e.length,a=e.reduce((o,n)=>o+(n-s)**2,0)/e.length;return e.map(o=>(o-s)/Math.sqrt(a+1e-7))}async _call(e){Z(e,"Wav2Vec2FeatureExtractor"),e instanceof Float64Array&&(e=new Float32Array(e));let t=e;this.config.do_normalize&&(t=this._zero_mean_unit_var_norm(t));const s=[1,t.length];return{input_values:new C("float32",t,s),attention_mask:new C("int64",new BigInt64Array(t.length).fill(1n),s)}}}class Bt extends N{constructor(e){super(e);const t=this.config.sampling_rate,s=Q(256,this.config.num_mel_bins,20,Math.floor(t/2),t,null,"kaldi",!0);for(let a=0;a<s.length;++a)s[a].push(0);this.mel_filters=s,this.window=se(400,"povey",{periodic:!1})}_extract_fbank_features(e,t){return e=e.map(s=>s*32768),te(e,this.window,400,160,{fft_length:512,power:2,center:!1,preemphasis:.97,mel_filters:this.mel_filters,log_mel:"log",mel_floor:1192092955078125e-22,remove_dc_offset:!0,max_num_frames:t,transpose:!0})}async _call(e,{padding:t=!0,pad_to_multiple_of:s=2,do_normalize_per_mel_bins:a=!0,return_attention_mask:o=!0}={}){Z(e,"SeamlessM4TFeatureExtractor");let n=this._extract_fbank_features(e,this.config.max_length);if(a){const[h,m]=n.dims;for(let _=0;_<m;++_){let g=0;for(let y=0;y<h;++y)g+=n.data[y*m+_];const M=g/h;let b=0;for(let y=0;y<h;++y)b+=(n.data[y*m+_]-M)**2;b/=h-1;const w=Math.sqrt(b+1e-7);for(let y=0;y<h;++y){const T=y*m+_;n.data[T]=(n.data[T]-M)/w}}}let r;if(t){const[h,m]=n.dims,_=h%s;if(_>0){const g=new Float32Array(m*(h+_));g.set(n.data),g.fill(this.config.padding_value,n.data.length);const M=h+_;n={data:g,dims:[M,m]},o&&(r=new C("int64",new BigInt64Array(M),[1,M]),r.data.fill(1n,0,h))}}const[l,c]=n.dims,d=this.config.stride;if(l%d!==0)throw new Error(`The number of frames (${l}) must be a multiple of the stride (${d}).`);const p=new C("float32",n.data,n.dims).view(1,Math.floor(l/d),c*d),u={input_features:p};if(o){const h=p.dims[1],m=new C("int64",new BigInt64Array(h),[1,h]);if(r)for(let _=1,g=0;_<l;_+=d,++g)m.data[g]=r.data[_];else m.data.fill(1n);u.attention_mask=m}return u}}class Rt extends N{constructor(e){super(e);const t=this.config.sampling_rate,s=Q(256,this.config.num_mel_bins,20,Math.floor(t/2),t,null,"kaldi",!0);for(let a=0;a<s.length;++a)s[a].push(0);this.mel_filters=s,this.window=se(400,"hann",{periodic:!1}),this.mean=this.config.mean,this.std=this.config.std}_extract_fbank_features(e,t){return te(e,this.window,400,160,{fft_length:512,power:2,center:!1,preemphasis:.97,mel_filters:this.mel_filters,log_mel:"log",mel_floor:1192092955078125e-22,remove_dc_offset:!0,max_num_frames:t,transpose:!0})}async _call(e){Z(e,"ASTFeatureExtractor");const t=this._extract_fbank_features(e,this.config.max_length);if(this.config.do_normalize){const s=this.std*2;for(let a=0;a<t.data.length;++a)t.data[a]=(t.data[a]-this.mean)/s}return{input_values:new C("float32",t.data,[1,...t.dims])}}}class Dt extends N{constructor(e){super(e),this.mel_filters=Q(this.config.nb_frequency_bins,this.config.feature_size,this.config.frequency_min,this.config.frequency_max,this.config.sampling_rate,null,"htk"),this.mel_filters_slaney=Q(this.config.nb_frequency_bins,this.config.feature_size,this.config.frequency_min,this.config.frequency_max,this.config.sampling_rate,"slaney","slaney"),this.window=se(this.config.fft_window_size,"hann")}_get_input_mel(e,t,s,a){let o,n=!1;const r=e.length-t;if(r>0)if(s==="rand_trunc"){n=!0;const l=Math.floor(Math.random()*(r+1));e=e.subarray(l,l+t),o=this._extract_fbank_features(e,this.mel_filters_slaney,this.config.nb_max_samples),o.dims=[1,...o.dims]}else throw new Error(`Truncation strategy "${s}" not implemented`);else{if(r<0){let l=new Float64Array(t);if(l.set(e),a==="repeat")for(let c=e.length;c<t;c+=e.length)l.set(e.subarray(0,Math.min(e.length,t-c)),c);else if(a==="repeatpad")for(let c=e.length;c<-r;c+=e.length)l.set(e,c);e=l}if(s==="fusion")throw new Error(`Truncation strategy "${s}" not implemented`);o=this._extract_fbank_features(e,this.mel_filters_slaney,this.config.nb_max_samples),o.dims=[1,...o.dims]}return{...o,longer:n}}_extract_fbank_features(e,t,s=null){return te(e,this.window,this.config.fft_window_size,this.config.hop_length,{power:2,mel_filters:t,log_mel:"dB",max_num_frames:s,do_pad:!1,transpose:!0})}async _call(e,{max_length:t=null}={}){Z(e,"ClapFeatureExtractor");const s=this._get_input_mel(e,t??this.config.nb_max_samples,this.config.truncation,this.config.padding);return{input_features:new C("float32",s.data,[1,...s.dims])}}}class Ot extends N{}class X extends re{constructor(e){super(),this.feature_extractor=e}async _call(e,...t){return await this.feature_extractor(e,...t)}}class jt extends X{async _call(...e){return await this.feature_extractor(...e)}post_process_masks(...e){return this.feature_extractor.post_process_masks(...e)}reshape_input_points(...e){return this.feature_extractor.reshape_input_points(...e)}}class Vt extends X{async _call(e){return await this.feature_extractor(e)}}class Nt extends X{async _call(e){return await this.feature_extractor(e)}}class qt extends X{async _call(e){return await this.feature_extractor(e)}}class Gt extends X{}class v{static FEATURE_EXTRACTOR_CLASS_MAPPING={ImageFeatureExtractor:F,WhisperFeatureExtractor:Lt,ViTFeatureExtractor:wt,MobileViTFeatureExtractor:ye,MobileViTImageProcessor:xt,OwlViTFeatureExtractor:Te,Owlv2ImageProcessor:Ft,CLIPFeatureExtractor:_t,ChineseCLIPFeatureExtractor:gt,SiglipImageProcessor:Mt,ConvNextFeatureExtractor:we,ConvNextImageProcessor:bt,SegformerFeatureExtractor:ht,BitImageProcessor:pt,DPTImageProcessor:ft,DPTFeatureExtractor:be,GLPNFeatureExtractor:mt,BeitFeatureExtractor:At,DeiTFeatureExtractor:kt,DetrFeatureExtractor:Ct,YolosFeatureExtractor:zt,DonutFeatureExtractor:xe,NougatImageProcessor:Pt,EfficientNetImageProcessor:Tt,ViTImageProcessor:yt,VitMatteImageProcessor:Et,SamImageProcessor:St,Swin2SRImageProcessor:vt,Wav2Vec2FeatureExtractor:It,SeamlessM4TFeatureExtractor:Bt,SpeechT5FeatureExtractor:Ot,ASTFeatureExtractor:Rt,ClapFeatureExtractor:Dt};static PROCESSOR_CLASS_MAPPING={WhisperProcessor:Vt,Wav2Vec2ProcessorWithLM:Nt,SamProcessor:jt,SpeechT5Processor:qt,OwlViTProcessor:Gt};static async from_pretrained(e,{progress_callback:t=null,config:s=null,cache_dir:a=null,local_files_only:o=!1,revision:n="main"}={}){let r=s??await ze(e,"preprocessor_config.json",!0,{progress_callback:t,cache_dir:a,local_files_only:o,revision:n}),l=r.feature_extractor_type??r.image_processor_type,c=this.FEATURE_EXTRACTOR_CLASS_MAPPING[l];if(!c)if(r.size!==void 0)console.warn(`Feature extractor type "${l}" not found, assuming ImageFeatureExtractor due to size parameter in config.`),c=F;else throw new Error(`Unknown Feature Extractor type: ${l}`);let d=this.PROCESSOR_CLASS_MAPPING[r.processor_class]??X,f=new c(r);return new d(f)}}async function D(i){return Array.isArray(i)||(i=[i]),await Promise.all(i.map(e=>H.read(e)))}async function K(i,e){return Array.isArray(i)||(i=[i]),await Promise.all(i.map(t=>typeof t=="string"||t instanceof URL?ot(t,e):t instanceof Float64Array?new Float32Array(t):t))}function Fe(i,e){e&&(i=i.map(n=>n|0));const[t,s,a,o]=i;return{xmin:t,ymin:s,xmax:a,ymax:o}}class k extends re{constructor({task:e,model:t,tokenizer:s=null,processor:a=null}){super(),this.task=e,this.model=t,this.tokenizer=s,this.processor=a}async dispose(){await this.model.dispose()}}class Wt extends k{constructor(e){super(e)}async _call(e,{topk:t=1}={}){const s=this.tokenizer(e,{padding:!0,truncation:!0}),a=await this.model(s),o=this.model.config.problem_type==="multi_label_classification"?l=>l.sigmoid().data:l=>E(l.data),n=this.model.config.id2label,r=[];for(const l of a.logits){const c=o(l),f=ee(c,t).map(p=>({label:n[p[0]],score:p[1]}));t===1?r.push(...f):r.push(f)}return Array.isArray(e)||t===1?r:r[0]}}class Xt extends k{constructor(e){super(e)}async _call(e,{ignore_labels:t=["O"]}={}){const s=Array.isArray(e),a=this.tokenizer(s?e:[e],{padding:!0,truncation:!0}),n=(await this.model(a)).logits,r=this.model.config.id2label,l=[];for(let c=0;c<n.dims[0];++c){const d=a.input_ids[c],f=n[c],p=[];for(let u=0;u<f.dims[0];++u){const h=f[u],m=j(h.data)[1],_=r?r[m]:`LABEL_${m}`;if(t.includes(_))continue;const g=this.tokenizer.decode([d[u].item()],{skip_special_tokens:!0});if(g==="")continue;const M=E(h.data);p.push({entity:_,score:M[m],index:u,word:g,start:null,end:null})}l.push(p)}return s?l:l[0]}}class $t extends k{constructor(e){super(e)}async _call(e,t,{topk:s=1}={}){const a=this.tokenizer(e,{text_pair:t,padding:!0,truncation:!0}),o=await this.model(a),n=[];for(let r=0;r<o.start_logits.dims[0];++r){const l=a.input_ids[r],c=l.indexOf(this.tokenizer.sep_token_id),d=Array.from(E(o.start_logits[r].data)).map((u,h)=>[u,h]).filter(u=>u[1]>c),f=Array.from(E(o.end_logits[r].data)).map((u,h)=>[u,h]).filter(u=>u[1]>c),p=st(d,f).filter(u=>u[0][1]<=u[1][1]).map(u=>[u[0][1],u[1][1],u[0][0]*u[1][0]]).sort((u,h)=>h[2]-u[2]);for(let u=0;u<Math.min(p.length,s);++u){const[h,m,_]=p[u],g=[...l].slice(h,m+1),M=this.tokenizer.decode(g,{skip_special_tokens:!0});n.push({answer:M,score:_})}}return s===1?n[0]:n}}class Ut extends k{constructor(e){super(e)}async _call(e,{topk:t=5}={}){const s=this.tokenizer(e,{padding:!0,truncation:!0}),a=await this.model(s),o=[];for(let n=0;n<s.input_ids.dims[0];++n){const r=s.input_ids[n],l=r.indexOf(this.tokenizer.mask_token_id);if(l===-1)throw Error(`Mask token (${this.tokenizer.mask_token}) not found in text.`);const d=a.logits[n][l],f=ee(E(d.data),t);o.push(f.map(p=>{const u=[...r];return u[l]=p[0],{score:p[1],token:p[0],token_str:this.tokenizer.model.vocab[p[0]],sequence:this.tokenizer.decode(u,{skip_special_tokens:!0})}}))}return Array.isArray(e)?o:o[0]}}class ce extends k{_key="generated_text";constructor(e){super(e)}async _call(e,t={}){Array.isArray(e)||(e=[e]),this.model.config.prefix&&(e=e.map(l=>this.model.config.prefix+l));const s=this.model.config.task_specific_params;s&&s[this.task]&&s[this.task].prefix&&(e=e.map(l=>s[this.task].prefix+l));const a=this.tokenizer,o={padding:!0,truncation:!0};let n;this instanceof ke&&"_build_translation_inputs"in a?n=a._build_translation_inputs(e,o,t).input_ids:n=a(e,o).input_ids;const r=await this.model.generate(n,t);return a.batch_decode(r,{skip_special_tokens:!0}).map(l=>({[this._key]:l}))}}class Ht extends ce{_key="summary_text";constructor(e){super(e)}}class ke extends ce{_key="translation_text";constructor(e){super(e)}}function _e(i){return Array.isArray(i)&&i.every(e=>"role"in e&&"content"in e)}class Qt extends k{constructor(e){super(e)}async _call(e,t={}){let s=!1,a=!1,o;if(typeof e=="string")o=e=[e];else if(Array.isArray(e)&&e.every(h=>typeof h=="string"))s=!0,o=e;else{if(_e(e))e=[e];else if(Array.isArray(e)&&e.every(_e))s=!0;else throw new Error("Input must be a string, an array of strings, a Chat, or an array of Chats");a=!0,o=e.map(h=>this.tokenizer.apply_chat_template(h,{tokenize:!1,add_generation_prompt:!0}))}const n=t.add_special_tokens??!1,r=a?!1:t.return_full_text??!0;this.tokenizer.padding_side="left";const{input_ids:l,attention_mask:c}=this.tokenizer(o,{add_special_tokens:n,padding:!0,truncation:!0}),d=await this.model.generate(l,t,null,{inputs_attention_mask:c});let f=this.tokenizer.batch_decode(d,{skip_special_tokens:!0}),p;!r&&l.dims.at(-1)>0&&(p=this.tokenizer.batch_decode(l,{skip_special_tokens:!0}).map(h=>h.length));const u=Array.from({length:e.length},h=>[]);for(let h=0;h<f.length;++h){const m=Math.floor(h/d.length*e.length);p&&(f[h]=f[h].slice(p[m])),u[m].push({generated_text:a?[...e[m],{role:"assistant",content:f[h]}]:f[h]})}return!s&&u.length===1?u[0]:u}}class Zt extends k{constructor(e){super(e),this.label2id=Object.fromEntries(Object.entries(this.model.config.label2id).map(([t,s])=>[t.toLowerCase(),s])),this.entailment_id=this.label2id.entailment,this.entailment_id===void 0&&(console.warn("Could not find 'entailment' in label2id mapping. Using 2 as entailment_id."),this.entailment_id=2),this.contradiction_id=this.label2id.contradiction??this.label2id.not_entailment,this.contradiction_id===void 0&&(console.warn("Could not find 'contradiction' in label2id mapping. Using 0 as contradiction_id."),this.contradiction_id=0)}async _call(e,t,{hypothesis_template:s="This example is {}.",multi_label:a=!1}={}){const o=Array.isArray(e);o||(e=[e]),Array.isArray(t)||(t=[t]);const n=t.map(c=>s.replace("{}",c)),r=a||t.length===1,l=[];for(const c of e){const d=[];for(const u of n){const h=this.tokenizer(c,{text_pair:u,padding:!0,truncation:!0}),m=await this.model(h);r?d.push([m.logits.data[this.contradiction_id],m.logits.data[this.entailment_id]]):d.push(m.logits.data[this.entailment_id])}const p=(r?d.map(u=>E(u)[1]):E(d)).map((u,h)=>[u,h]).sort((u,h)=>h[0]-u[0]);l.push({sequence:c,labels:p.map(u=>t[u[1]]),scores:p.map(u=>u[0])})}return o?l:l[0]}}class Jt extends k{constructor(e){super(e)}async _call(e,{pooling:t="none",normalize:s=!1,quantize:a=!1,precision:o="binary"}={}){const n=this.tokenizer(e,{padding:!0,truncation:!0}),r=await this.model(n);let l=r.last_hidden_state??r.logits??r.token_embeddings;if(t!=="none")if(t==="mean")l=Ke(l,n.attention_mask);else if(t==="cls")l=l.slice(null,0);else throw Error(`Pooling method '${t}' not supported.`);return s&&(l=l.normalize(2,-1)),a&&(l=et(l,o)),l}}class Yt extends k{constructor(e){super(e)}async _call(e,{pool:t=null}={}){const s=await D(e),{pixel_values:a}=await this.processor(s),o=await this.model({pixel_values:a});let n;if(t){if(!("pooler_output"in o))throw Error("No pooled output was returned. Make sure the model has a 'pooler' layer when using the 'pool' option.");n=o.pooler_output}else n=o.last_hidden_state??o.logits??o.image_embeds;return n}}class Kt extends k{constructor(e){super(e)}async _call(e,{topk:t=null}={}){const s=!Array.isArray(e),a=this.processor.feature_extractor.config.sampling_rate,o=await K(e,a),n=this.model.config.id2label,r=[];for(const l of o){const c=await this.processor(l),f=(await this.model(c)).logits[0],u=ee(E(f.data),t).map(h=>({label:n[h[0]],score:h[1]}));t===1?r.push(...u):r.push(u)}return!s||t===1?r:r[0]}}class es extends k{constructor(e){super(e)}async _call(e,t,{hypothesis_template:s="This is a sound of {}."}={}){const a=!Array.isArray(e);a&&(e=[e]);const o=t.map(d=>s.replace("{}",d)),n=this.tokenizer(o,{padding:!0,truncation:!0}),r=this.processor.feature_extractor.config.sampling_rate,l=await K(e,r),c=[];for(const d of l){const f=await this.processor(d),p=await this.model({...n,...f}),u=E(p.logits_per_audio.data);c.push([...u].map((h,m)=>({score:h,label:t[m]})))}return a?c[0]:c}}class ts extends k{constructor(e){super(e)}async _call(e,t={}){switch(this.model.config.model_type){case"whisper":return this._call_whisper(e,t);case"wav2vec2":case"wav2vec2-bert":case"unispeech":case"unispeech-sat":case"hubert":return this._call_wav2vec2(e,t);default:throw new Error(`AutomaticSpeechRecognitionPipeline does not support model type '${this.model.config.model_type}'.`)}}async _call_wav2vec2(e,t={}){t.language&&console.warn('`language` parameter is not yet supported for `wav2vec2` models, defaulting to "English".'),t.task&&console.warn('`task` parameter is not yet supported for `wav2vec2` models, defaulting to "transcribe".');const s=!Array.isArray(e);s&&(e=[e]);const a=this.processor.feature_extractor.config.sampling_rate,o=await K(e,a),n=[];for(const r of o){const l=await this.processor(r),d=(await this.model(l)).logits[0],f=[];for(const u of d)f.push(j(u.data)[1]);const p=this.tokenizer.decode(f);n.push({text:p})}return s?n[0]:n}async _call_whisper(e,t={}){const s=t.return_timestamps??!1,a=t.chunk_length_s??0,o=t.chunk_callback??null,n=t.force_full_sequences??!1;let r=t.stride_length_s??null;s==="word"&&(t.return_token_timestamps=!0);const l=he(t,"language",null),c=he(t,"task",null);if(l||c||s){if(t.forced_decoder_ids)throw new Error("Cannot specify `language`/`task`/`return_timestamps` and `forced_decoder_ids` at the same time.");const _=this.tokenizer.get_decoder_prompt_ids({language:l,task:c,no_timestamps:!s});_.length>0&&(t.forced_decoder_ids=_)}const d=!Array.isArray(e);d&&(e=[e]);const f=this.processor.feature_extractor.config.chunk_length/this.model.config.max_source_positions,p=this.processor.feature_extractor.config.hop_length,u=this.processor.feature_extractor.config.sampling_rate,h=await K(e,u),m=[];for(const _ of h){let g=[];if(a>0){if(r===null)r=a/6;else if(a<=r)throw Error("`chunk_length_s` must be larger than `stride_length_s`.");const w=u*a,y=u*r,T=w-2*y;let A=0;for(;A<_.length;){const B=_.subarray(A,A+w),q=await this.processor(B),R=A===0,G=A+T>=_.length;g.push({stride:[B.length,R?0:y,G?0:y],input_features:q.input_features,is_last:G}),A+=T}}else g=[{stride:[_.length,0,0],input_features:(await this.processor(_)).input_features,is_last:!0}];for(const w of g){t.num_frames=Math.floor(w.stride[0]/p);const y=await this.model.generate(w.input_features,t);s==="word"?(w.tokens=y.sequences[0],w.token_timestamps=y.token_timestamps.tolist()[0].map(T=>tt(T,2))):w.tokens=y[0],w.stride=w.stride.map(T=>T/u),o!==null&&o(w)}const[M,b]=this.tokenizer._decode_asr(g,{time_precision:f,return_timestamps:s,force_full_sequences:n});m.push({text:M,...b})}return d?m[0]:m}}class ss extends k{constructor(e){super(e)}async _call(e,t={}){const s=Array.isArray(e),a=await D(e),{pixel_values:o}=await this.processor(a),n=[];for(const r of o){r.dims=[1,...r.dims];const l=await this.model.generate(r,t),c=this.tokenizer.batch_decode(l,{skip_special_tokens:!0}).map(d=>({generated_text:d.trim()}));n.push(c)}return s?n:n[0]}}class os extends k{constructor(e){super(e)}async _call(e,{topk:t=1}={}){const s=Array.isArray(e),a=await D(e),{pixel_values:o}=await this.processor(a),n=await this.model({pixel_values:o}),r=this.model.config.id2label,l=[];for(const c of n.logits){const f=ee(E(c.data),t).map(p=>({label:r[p[0]],score:p[1]}));t===1?l.push(...f):l.push(f)}return s||t===1?l:l[0]}}class as extends k{constructor(e){super(e),this.subtasks_mapping={panoptic:"post_process_panoptic_segmentation",instance:"post_process_instance_segmentation",semantic:"post_process_semantic_segmentation"}}async _call(e,{threshold:t=.5,mask_threshold:s=.5,overlap_mask_area_threshold:a=.8,label_ids_to_fuse:o=null,target_sizes:n=null,subtask:r=null}={}){if(Array.isArray(e)&&e.length!==1)throw Error("Image segmentation pipeline currently only supports a batch size of 1.");const c=await D(e),d=c.map(g=>[g.height,g.width]),{pixel_values:f,pixel_mask:p}=await this.processor(c),u=await this.model({pixel_values:f,pixel_mask:p});let h=null;if(r!==null)h=this.subtasks_mapping[r];else for(let[g,M]of Object.entries(this.subtasks_mapping))if(M in this.processor.feature_extractor){h=this.processor.feature_extractor[M].bind(this.processor.feature_extractor),r=g;break}const m=this.model.config.id2label,_=[];if(r==="panoptic"||r==="instance"){const g=h(u,t,s,a,o,n??d)[0],M=g.segmentation;for(const b of g.segments_info){const w=new Uint8ClampedArray(M.data.length);for(let T=0;T<M.data.length;++T)M.data[T]===b.id&&(w[T]=255);const y=new H(w,M.dims[1],M.dims[0],1);_.push({score:b.score,label:m[b.label_id],mask:y})}}else if(r==="semantic"){const{segmentation:g,labels:M}=h(u,n??d)[0];for(const b of M){const w=new Uint8ClampedArray(g.data.length);for(let T=0;T<g.data.length;++T)g.data[T]===b&&(w[T]=255);const y=new H(w,g.dims[1],g.dims[0],1);_.push({score:null,label:m[b],mask:y})}}else throw Error(`Subtask ${r} not supported.`);return _}}class ns extends k{constructor(e){super(e)}async _call(e,t,{hypothesis_template:s="This is a photo of {}"}={}){const a=Array.isArray(e),o=await D(e),n=t.map(p=>s.replace("{}",p)),r=this.tokenizer(n,{padding:this.model.config.model_type==="siglip"?"max_length":!0,truncation:!0}),{pixel_values:l}=await this.processor(o),c=await this.model({...r,pixel_values:l}),d=this.model.config.model_type==="siglip"?p=>p.sigmoid().data:p=>E(p.data),f=[];for(const p of c.logits_per_image){const h=[...d(p)].map((m,_)=>({score:m,label:t[_]}));h.sort((m,_)=>_.score-m.score),f.push(h)}return a?f:f[0]}}class is extends k{constructor(e){super(e)}async _call(e,{threshold:t=.9,percentage:s=!1}={}){const a=Array.isArray(e);if(a&&e.length!==1)throw Error("Object detection pipeline currently only supports a batch size of 1.");const o=await D(e),n=s?null:o.map(u=>[u.height,u.width]),{pixel_values:r,pixel_mask:l}=await this.processor(o),c=await this.model({pixel_values:r,pixel_mask:l}),d=this.processor.feature_extractor.post_process_object_detection(c,t,n),f=this.model.config.id2label,p=d.map(u=>u.boxes.map((h,m)=>({score:u.scores[m],label:f[u.classes[m]],box:Fe(h,!s)})));return a?p:p[0]}}class rs extends k{constructor(e){super(e)}async _call(e,t,{threshold:s=.1,topk:a=null,percentage:o=!1}={}){const n=Array.isArray(e),r=await D(e),l=this.tokenizer(t,{padding:!0,truncation:!0}),c=await this.processor(r),d=[];for(let f=0;f<r.length;++f){const p=r[f],u=o?null:[[p.height,p.width]],h=c.pixel_values[f].unsqueeze_(0),m=await this.model({...l,pixel_values:h}),_=this.processor.feature_extractor.post_process_object_detection(m,s,u,!0)[0];let g=_.boxes.map((M,b)=>({score:_.scores[b],label:t[_.classes[b]],box:Fe(M,!o)})).sort((M,b)=>b.score-M.score);a!==null&&(g=g.slice(0,a)),d.push(g)}return n?d:d[0]}}class ls extends k{constructor(e){super(e)}async _call(e,t,s={}){const a=(await D(e))[0],{pixel_values:o}=await this.processor(a),n=`<s_docvqa><s_question>${t}</s_question><s_answer>`,r=this.tokenizer(n,{add_special_tokens:!1,padding:!0,truncation:!0}).input_ids,l=await this.model.generate(o,{...s,decoder_input_ids:r,max_length:this.model.config.decoder.max_position_embeddings}),d=this.tokenizer.batch_decode(l)[0].match(/<s_answer>(.*?)<\/s_answer>/);let f=null;return d&&d.length>=2&&(f=d[1].trim()),[{answer:f}]}}class cs extends k{DEFAULT_VOCODER_ID="Xenova/speecht5_hifigan";constructor(e){super(e),this.vocoder=e.vocoder??null}async _call(e,{speaker_embeddings:t=null}={}){return this.processor?this._call_text_to_spectrogram(e,{speaker_embeddings:t}):this._call_text_to_waveform(e)}async _call_text_to_waveform(e){const t=this.tokenizer(e,{padding:!0,truncation:!0}),{waveform:s}=await this.model(t),a=this.model.config.sampling_rate;return{audio:s.data,sampling_rate:a}}async _call_text_to_spectrogram(e,{speaker_embeddings:t}){if(this.vocoder||(console.log("No vocoder specified, using default HifiGan vocoder."),this.vocoder=await $.from_pretrained(this.DEFAULT_VOCODER_ID,{quantized:!1})),(typeof t=="string"||t instanceof URL)&&(t=new Float32Array(await(await fetch(t)).arrayBuffer())),t instanceof Float32Array)t=new C("float32",t,[1,t.length]);else if(!(t instanceof C))throw new Error("Speaker embeddings must be a `Tensor`, `Float32Array`, `string`, or `URL`.");const{input_ids:s}=this.tokenizer(e,{padding:!0,truncation:!0}),{waveform:a}=await this.model.generate_speech(s,t,{vocoder:this.vocoder}),o=this.processor.feature_extractor.config.sampling_rate;return{audio:a.data,sampling_rate:o}}}class ds extends k{constructor(e){super(e)}async _call(e){const t=await D(e),s=await this.processor(t),a=await this.model(s),o=[];for(const n of a.reconstruction){const r=n.squeeze().clamp_(0,1).mul_(255).round_().to("uint8");o.push(H.fromTensor(r))}return o.length>1?o:o[0]}}class us extends k{constructor(e){super(e)}async _call(e){const t=await D(e),s=await this.processor(t),{predicted_depth:a}=await this.model(s),o=[];for(let n=0;n<t.length;++n){const r=U(a[n],t[n].size.reverse(),"bilinear",!1),l=r.mul_(255/j(r.data)[0]).to("uint8");o.push({predicted_depth:a[n],depth:H.fromTensor(l)})}return o.length>1?o:o[0]}}const ge=Object.freeze({"text-classification":{tokenizer:S,pipeline:Wt,model:ue,default:{model:"Xenova/distilbert-base-uncased-finetuned-sst-2-english"},type:"text"},"token-classification":{tokenizer:S,pipeline:Xt,model:Ye,default:{model:"Xenova/bert-base-multilingual-cased-ner-hrl"},type:"text"},"question-answering":{tokenizer:S,pipeline:$t,model:Je,default:{model:"Xenova/distilbert-base-cased-distilled-squad"},type:"text"},"fill-mask":{tokenizer:S,pipeline:Ut,model:Ze,default:{model:"Xenova/bert-base-uncased"},type:"text"},summarization:{tokenizer:S,pipeline:Ht,model:oe,default:{model:"Xenova/distilbart-cnn-6-6"},type:"text"},translation:{tokenizer:S,pipeline:ke,model:oe,default:{model:"Xenova/t5-small"},type:"text"},"text2text-generation":{tokenizer:S,pipeline:ce,model:oe,default:{model:"Xenova/flan-t5-small"},type:"text"},"text-generation":{tokenizer:S,pipeline:Qt,model:Qe,default:{model:"Xenova/gpt2"},type:"text"},"zero-shot-classification":{tokenizer:S,pipeline:Zt,model:ue,default:{model:"Xenova/distilbert-base-uncased-mnli"},type:"text"},"audio-classification":{pipeline:Kt,model:He,processor:v,default:{model:"Xenova/wav2vec2-base-superb-ks"},type:"audio"},"zero-shot-audio-classification":{tokenizer:S,pipeline:es,model:$,processor:v,default:{model:"Xenova/clap-htsat-unfused"},type:"multimodal"},"automatic-speech-recognition":{tokenizer:S,pipeline:ts,model:[$e,Ue],processor:v,default:{model:"Xenova/whisper-tiny.en"},type:"multimodal"},"text-to-audio":{tokenizer:S,pipeline:cs,model:[We,Xe],processor:[v,null],default:{model:"Xenova/speecht5_tts"},type:"text"},"image-to-text":{tokenizer:S,pipeline:ss,model:Ge,processor:v,default:{model:"Xenova/vit-gpt2-image-captioning"},type:"multimodal"},"image-classification":{pipeline:os,model:qe,processor:v,default:{model:"Xenova/vit-base-patch16-224"},type:"multimodal"},"image-segmentation":{pipeline:as,model:[Ve,Ne],processor:v,default:{model:"Xenova/detr-resnet-50-panoptic"},type:"multimodal"},"zero-shot-image-classification":{tokenizer:S,pipeline:ns,model:$,processor:v,default:{model:"Xenova/clip-vit-base-patch32"},type:"multimodal"},"object-detection":{pipeline:is,model:je,processor:v,default:{model:"Xenova/detr-resnet-50"},type:"multimodal"},"zero-shot-object-detection":{tokenizer:S,pipeline:rs,model:Oe,processor:v,default:{model:"Xenova/owlvit-base-patch32"},type:"multimodal"},"document-question-answering":{tokenizer:S,pipeline:ls,model:De,processor:v,default:{model:"Xenova/donut-base-finetuned-docvqa"},type:"multimodal"},"image-to-image":{pipeline:ds,model:Re,processor:v,default:{model:"Xenova/swin2SR-classical-sr-x2-64"},type:"image"},"depth-estimation":{pipeline:us,model:Be,processor:v,default:{model:"Xenova/dpt-large"},type:"image"},"feature-extraction":{tokenizer:S,pipeline:Jt,model:$,default:{model:"Xenova/all-MiniLM-L6-v2"},type:"text"},"image-feature-extraction":{processor:v,pipeline:Yt,model:[Ie,$],default:{model:"Xenova/vit-base-patch16-224-in21k"},type:"image"}}),hs=Object.freeze({"sentiment-analysis":"text-classification",ner:"token-classification",asr:"automatic-speech-recognition","text-to-speech":"text-to-audio",embeddings:"feature-extraction"});async function ms(i,e=null,{quantized:t=!0,progress_callback:s=null,config:a=null,cache_dir:o=null,local_files_only:n=!1,revision:r="main",model_file_name:l=null}={}){i=hs[i]??i;const c=ge[i.split("_",1)[0]];if(!c)throw Error(`Unsupported pipeline: ${i}. Must be one of [${Object.keys(ge)}]`);e||(e=c.default.model,console.log(`No model specified. Using default model: "${e}".`));const d={quantized:t,progress_callback:s,config:a,cache_dir:o,local_files_only:n,revision:r,model_file_name:l},f=new Map([["tokenizer",c.tokenizer],["model",c.model],["processor",c.processor]]),p=await fs(f,e,d);p.task=i,Le(s,{status:"ready",task:i,model:e});const u=c.pipeline;return new u(p)}async function fs(i,e,t){const s=Object.create(null),a=[];for(let[o,n]of i.entries()){if(!n)continue;let r;Array.isArray(n)?r=new Promise(async(l,c)=>{let d;for(let f of n){if(f===null){l(null);return}try{l(await f.from_pretrained(e,t));return}catch(p){d=p}}c(d)}):r=n.from_pretrained(e,t),s[o]=r,a.push(r)}await Promise.all(a);for(let[o,n]of Object.entries(s))s[o]=await n;return s}export{Rt as ASTFeatureExtractor,Ms as ASTForAudioClassification,bs as ASTModel,ws as ASTPreTrainedModel,ys as AlbertForMaskedLM,Ts as AlbertForQuestionAnswering,xs as AlbertForSequenceClassification,Fs as AlbertModel,ks as AlbertPreTrainedModel,As as AlbertTokenizer,Kt as AudioClassificationPipeline,Ps as AutoConfig,$ as AutoModel,He as AutoModelForAudioClassification,Ue as AutoModelForCTC,Qe as AutoModelForCausalLM,Be as AutoModelForDepthEstimation,De as AutoModelForDocumentQuestionAnswering,qe as AutoModelForImageClassification,Ie as AutoModelForImageFeatureExtraction,Ve as AutoModelForImageSegmentation,Re as AutoModelForImageToImage,Ze as AutoModelForMaskedLM,je as AutoModelForObjectDetection,Je as AutoModelForQuestionAnswering,Ne as AutoModelForSemanticSegmentation,oe as AutoModelForSeq2SeqLM,ue as AutoModelForSequenceClassification,$e as AutoModelForSpeechSeq2Seq,Xe as AutoModelForTextToSpectrogram,We as AutoModelForTextToWaveform,Ye as AutoModelForTokenClassification,Ge as AutoModelForVision2Seq,Oe as AutoModelForZeroShotObjectDetection,v as AutoProcessor,S as AutoTokenizer,ts as AutomaticSpeechRecognitionPipeline,Cs as BartForConditionalGeneration,zs as BartForSequenceClassification,Ss as BartModel,vs as BartPretrainedModel,Es as BartTokenizer,At as BeitFeatureExtractor,Ls as BeitForImageClassification,Is as BeitModel,Bs as BeitPreTrainedModel,Rs as BertForMaskedLM,Ds as BertForQuestionAnswering,Os as BertForSequenceClassification,js as BertForTokenClassification,Vs as BertModel,Ns as BertPreTrainedModel,qs as BertTokenizer,pt as BitImageProcessor,Gs as BlenderbotForConditionalGeneration,Ws as BlenderbotModel,Xs as BlenderbotPreTrainedModel,$s as BlenderbotSmallForConditionalGeneration,Us as BlenderbotSmallModel,Hs as BlenderbotSmallPreTrainedModel,Qs as BlenderbotSmallTokenizer,Zs as BlenderbotTokenizer,Js as BloomForCausalLM,Ys as BloomModel,Ks as BloomPreTrainedModel,eo as BloomTokenizer,_t as CLIPFeatureExtractor,to as CLIPModel,so as CLIPPreTrainedModel,oo as CLIPSegForImageSegmentation,ao as CLIPSegModel,no as CLIPSegPreTrainedModel,io as CLIPTextModelWithProjection,ro as CLIPTokenizer,lo as CLIPVisionModelWithProjection,co as CamembertForMaskedLM,uo as CamembertForQuestionAnswering,ho as CamembertForSequenceClassification,fo as CamembertForTokenClassification,po as CamembertModel,mo as CamembertPreTrainedModel,_o as CamembertTokenizer,go as CausalLMOutput,gt as ChineseCLIPFeatureExtractor,Mo as ChineseCLIPModel,bo as ChineseCLIPPreTrainedModel,wo as ClapAudioModelWithProjection,Dt as ClapFeatureExtractor,yo as ClapModel,To as ClapPreTrainedModel,xo as ClapTextModelWithProjection,Fo as CodeGenForCausalLM,ko as CodeGenModel,Ao as CodeGenPreTrainedModel,Po as CodeGenTokenizer,Co as CodeLlamaTokenizer,zo as CohereTokenizer,So as ConvBertForMaskedLM,vo as ConvBertForQuestionAnswering,Eo as ConvBertForSequenceClassification,Lo as ConvBertForTokenClassification,Io as ConvBertModel,Bo as ConvBertPreTrainedModel,Ro as ConvBertTokenizer,we as ConvNextFeatureExtractor,Do as ConvNextForImageClassification,bt as ConvNextImageProcessor,Oo as ConvNextModel,jo as ConvNextPreTrainedModel,Vo as ConvNextV2ForImageClassification,No as ConvNextV2Model,qo as ConvNextV2PreTrainedModel,be as DPTFeatureExtractor,Go as DPTForDepthEstimation,ft as DPTImageProcessor,Wo as DPTModel,Xo as DPTPreTrainedModel,$o as DebertaForMaskedLM,Uo as DebertaForQuestionAnswering,Ho as DebertaForSequenceClassification,Qo as DebertaForTokenClassification,Zo as DebertaModel,Jo as DebertaPreTrainedModel,Yo as DebertaTokenizer,Ko as DebertaV2ForMaskedLM,ea as DebertaV2ForQuestionAnswering,ta as DebertaV2ForSequenceClassification,sa as DebertaV2ForTokenClassification,oa as DebertaV2Model,aa as DebertaV2PreTrainedModel,na as DebertaV2Tokenizer,kt as DeiTFeatureExtractor,ia as DeiTForImageClassification,ra as DeiTModel,la as DeiTPreTrainedModel,ca as DepthAnythingForDepthEstimation,da as DepthAnythingPreTrainedModel,us as DepthEstimationPipeline,Ct as DetrFeatureExtractor,ua as DetrForObjectDetection,ha as DetrForSegmentation,fa as DetrModel,pa as DetrObjectDetectionOutput,ma as DetrPreTrainedModel,_a as DetrSegmentationOutput,ga as Dinov2ForImageClassification,Ma as Dinov2Model,ba as Dinov2PreTrainedModel,wa as DistilBertForMaskedLM,ya as DistilBertForQuestionAnswering,Ta as DistilBertForSequenceClassification,xa as DistilBertForTokenClassification,Fa as DistilBertModel,ka as DistilBertPreTrainedModel,Aa as DistilBertTokenizer,ls as DocumentQuestionAnsweringPipeline,xe as DonutFeatureExtractor,Pa as DonutSwinModel,Ca as DonutSwinPreTrainedModel,za as EfficientNetForImageClassification,Tt as EfficientNetImageProcessor,Sa as EfficientNetModel,va as EfficientNetPreTrainedModel,Ea as ElectraForMaskedLM,La as ElectraForQuestionAnswering,Ia as ElectraForSequenceClassification,Ba as ElectraForTokenClassification,Ra as ElectraModel,Da as ElectraPreTrainedModel,Oa as ElectraTokenizer,ja as EsmForMaskedLM,Va as EsmForSequenceClassification,Na as EsmForTokenClassification,qa as EsmModel,Ga as EsmPreTrainedModel,Wa as EsmTokenizer,Pe as FFT,Xa as FalconForCausalLM,$a as FalconModel,Ua as FalconPreTrainedModel,Ha as FalconTokenizer,Qa as FastViTForImageClassification,Za as FastViTModel,Ja as FastViTPreTrainedModel,Jt as FeatureExtractionPipeline,N as FeatureExtractor,Ut as FillMaskPipeline,mt as GLPNFeatureExtractor,Ya as GLPNForDepthEstimation,Ka as GLPNModel,en as GLPNPreTrainedModel,tn as GPT2LMHeadModel,sn as GPT2Model,on as GPT2PreTrainedModel,an as GPT2Tokenizer,nn as GPTBigCodeForCausalLM,rn as GPTBigCodeModel,ln as GPTBigCodePreTrainedModel,cn as GPTJForCausalLM,dn as GPTJModel,un as GPTJPreTrainedModel,hn as GPTNeoForCausalLM,fn as GPTNeoModel,pn as GPTNeoPreTrainedModel,mn as GPTNeoXForCausalLM,_n as GPTNeoXModel,gn as GPTNeoXPreTrainedModel,Mn as GPTNeoXTokenizer,bn as GemmaTokenizer,wn as Grok1Tokenizer,yn as HerbertTokenizer,Tn as HubertForCTC,xn as HubertForSequenceClassification,Fn as HubertModel,os as ImageClassificationPipeline,Yt as ImageFeatureExtractionPipeline,F as ImageFeatureExtractor,kn as ImageMattingOutput,as as ImageSegmentationPipeline,ds as ImageToImagePipeline,ss as ImageToTextPipeline,An as LlamaForCausalLM,Pn as LlamaModel,Cn as LlamaPreTrainedModel,zn as LlamaTokenizer,Sn as LongT5ForConditionalGeneration,vn as LongT5Model,En as LongT5PreTrainedModel,Ln as M2M100ForConditionalGeneration,In as M2M100Model,Bn as M2M100PreTrainedModel,Rn as M2M100Tokenizer,Dn as MBart50Tokenizer,On as MBartForCausalLM,jn as MBartForConditionalGeneration,Vn as MBartForSequenceClassification,Nn as MBartModel,qn as MBartPreTrainedModel,Gn as MBartTokenizer,Wn as MPNetForMaskedLM,Xn as MPNetForQuestionAnswering,$n as MPNetForSequenceClassification,Un as MPNetForTokenClassification,Hn as MPNetModel,Qn as MPNetPreTrainedModel,Zn as MPNetTokenizer,Jn as MT5ForConditionalGeneration,Yn as MT5Model,Kn as MT5PreTrainedModel,ei as MarianMTModel,ti as MarianModel,si as MarianPreTrainedModel,oi as MarianTokenizer,ai as MaskedLMOutput,ni as MistralForCausalLM,ii as MistralModel,ri as MistralPreTrainedModel,li as MobileBertForMaskedLM,ci as MobileBertForQuestionAnswering,di as MobileBertForSequenceClassification,ui as MobileBertModel,hi as MobileBertPreTrainedModel,fi as MobileBertTokenizer,ye as MobileViTFeatureExtractor,pi as MobileViTForImageClassification,xt as MobileViTImageProcessor,mi as MobileViTModel,_i as MobileViTPreTrainedModel,gi as MobileViTV2ForImageClassification,Mi as MobileViTV2Model,bi as MobileViTV2PreTrainedModel,wi as ModelOutput,yi as MptForCausalLM,Ti as MptModel,xi as MptPreTrainedModel,Fi as NllbTokenizer,ki as NomicBertModel,Ai as NomicBertPreTrainedModel,Pt as NougatImageProcessor,Pi as NougatTokenizer,Ci as OPTForCausalLM,zi as OPTModel,Si as OPTPreTrainedModel,is as ObjectDetectionPipeline,Te as OwlViTFeatureExtractor,vi as OwlViTForObjectDetection,Ei as OwlViTModel,Li as OwlViTPreTrainedModel,Gt as OwlViTProcessor,Ii as Owlv2ForObjectDetection,Ft as Owlv2ImageProcessor,Bi as Owlv2Model,Ri as Owlv2PreTrainedModel,Di as PhiForCausalLM,Oi as PhiModel,ji as PhiPreTrainedModel,k as Pipeline,Vi as PreTrainedModel,Ni as PreTrainedTokenizer,qi as PretrainedConfig,Gi as PretrainedMixin,X as Processor,Wi as QuestionAnsweringModelOutput,$t as QuestionAnsweringPipeline,Xi as Qwen2ForCausalLM,$i as Qwen2Model,Ui as Qwen2PreTrainedModel,Hi as Qwen2Tokenizer,H as RawImage,Qi as ResNetForImageClassification,Zi as ResNetModel,Ji as ResNetPreTrainedModel,Yi as RoFormerForMaskedLM,Ki as RoFormerForQuestionAnswering,er as RoFormerForSequenceClassification,tr as RoFormerForTokenClassification,sr as RoFormerModel,or as RoFormerPreTrainedModel,ar as RoFormerTokenizer,nr as RobertaForMaskedLM,ir as RobertaForQuestionAnswering,rr as RobertaForSequenceClassification,lr as RobertaForTokenClassification,cr as RobertaModel,dr as RobertaPreTrainedModel,ur as RobertaTokenizer,St as SamImageProcessor,hr as SamImageSegmentationOutput,fr as SamModel,pr as SamPreTrainedModel,jt as SamProcessor,Bt as SeamlessM4TFeatureExtractor,ht as SegformerFeatureExtractor,mr as SegformerForImageClassification,_r as SegformerForSemanticSegmentation,gr as SegformerPreTrainedModel,Mr as Seq2SeqLMOutput,br as SequenceClassifierOutput,Mt as SiglipImageProcessor,wr as SiglipModel,yr as SiglipPreTrainedModel,Tr as SiglipTextModel,xr as SiglipTokenizer,Fr as SiglipVisionModel,Ot as SpeechT5FeatureExtractor,kr as SpeechT5ForSpeechToText,Ar as SpeechT5ForTextToSpeech,Pr as SpeechT5HifiGan,Cr as SpeechT5PreTrainedModel,qt as SpeechT5Processor,zr as SpeechT5Tokenizer,Sr as SqueezeBertForMaskedLM,vr as SqueezeBertForQuestionAnswering,Er as SqueezeBertForSequenceClassification,Lr as SqueezeBertModel,Ir as SqueezeBertPreTrainedModel,Br as SqueezeBertTokenizer,Rr as StableLmForCausalLM,Dr as StableLmPreTrainedModel,Or as Starcoder2ForCausalLM,jr as Starcoder2Model,Vr as Starcoder2PreTrainedModel,Ht as SummarizationPipeline,Nr as Swin2SRForImageSuperResolution,vt as Swin2SRImageProcessor,qr as Swin2SRModel,Gr as Swin2SRPreTrainedModel,Wr as SwinForImageClassification,Xr as SwinModel,$r as SwinPreTrainedModel,Ur as T5ForConditionalGeneration,Hr as T5Model,Qr as T5PreTrainedModel,Zr as T5Tokenizer,Jr as TableTransformerForObjectDetection,Yr as TableTransformerModel,Kr as TableTransformerObjectDetectionOutput,el as TableTransformerPreTrainedModel,C as Tensor,ce as Text2TextGenerationPipeline,Wt as TextClassificationPipeline,Qt as TextGenerationPipeline,cs as TextToAudioPipeline,Xt as TokenClassificationPipeline,tl as TokenClassifierOutput,sl as TokenizerModel,ol as TrOCRForCausalLM,al as TrOCRPreTrainedModel,ke as TranslationPipeline,nl as UniSpeechForCTC,il as UniSpeechForSequenceClassification,rl as UniSpeechModel,ll as UniSpeechPreTrainedModel,cl as UniSpeechSatForAudioFrameClassification,dl as UniSpeechSatForCTC,ul as UniSpeechSatForSequenceClassification,hl as UniSpeechSatModel,fl as UniSpeechSatPreTrainedModel,wt as ViTFeatureExtractor,pl as ViTForImageClassification,yt as ViTImageProcessor,ml as ViTModel,_l as ViTPreTrainedModel,gl as VisionEncoderDecoderModel,Ml as VitMatteForImageMatting,Et as VitMatteImageProcessor,bl as VitMattePreTrainedModel,wl as VitsModel,yl as VitsModelOutput,Tl as VitsPreTrainedModel,xl as VitsTokenizer,Fl as Wav2Vec2BertForCTC,kl as Wav2Vec2BertForSequenceClassification,Al as Wav2Vec2BertModel,Pl as Wav2Vec2BertPreTrainedModel,Cl as Wav2Vec2CTCTokenizer,It as Wav2Vec2FeatureExtractor,zl as Wav2Vec2ForAudioFrameClassification,Sl as Wav2Vec2ForCTC,vl as Wav2Vec2ForSequenceClassification,El as Wav2Vec2Model,Ll as Wav2Vec2PreTrainedModel,Nt as Wav2Vec2ProcessorWithLM,Il as WavLMForAudioFrameClassification,Bl as WavLMForCTC,Rl as WavLMForSequenceClassification,Dl as WavLMForXVector,Ol as WavLMModel,jl as WavLMPreTrainedModel,Lt as WhisperFeatureExtractor,Vl as WhisperForConditionalGeneration,Nl as WhisperModel,ql as WhisperPreTrainedModel,Vt as WhisperProcessor,Gl as WhisperTokenizer,Wl as XLMForQuestionAnswering,Xl as XLMForSequenceClassification,$l as XLMForTokenClassification,Ul as XLMModel,Hl as XLMPreTrainedModel,Ql as XLMRobertaForMaskedLM,Zl as XLMRobertaForQuestionAnswering,Jl as XLMRobertaForSequenceClassification,Yl as XLMRobertaForTokenClassification,Kl as XLMRobertaModel,ec as XLMRobertaPreTrainedModel,tc as XLMRobertaTokenizer,sc as XLMTokenizer,oc as XLMWithLMHeadModel,ac as XVectorOutput,zt as YolosFeatureExtractor,nc as YolosForObjectDetection,ic as YolosModel,rc as YolosObjectDetectionOutput,lc as YolosPreTrainedModel,es as ZeroShotAudioClassificationPipeline,Zt as ZeroShotClassificationPipeline,ns as ZeroShotImageClassificationPipeline,rs as ZeroShotObjectDetectionPipeline,Ee as bankers_round,Se as cat,cc as dynamicTimeWarping,dc as env,ee as getTopItems,fe as hanning,U as interpolate,uc as interpolate_data,hc as log_softmax,j as max,fc as mean,Ke as mean_pooling,pc as medianFilter,Q as mel_filter_bank,ve as min,mc as ones,_c as ones_like,gc as permute,Mc as permute_data,ms as pipeline,et as quantize_embeddings,ot as read_audio,tt as round,E as softmax,te as spectrogram,ie as stack,bc as std_mean,se as window_function};
